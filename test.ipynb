{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.utils import *\n",
    "from data.data_gatherer import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = \"/Users/owan/Desktop/ComputeCodeX/data/gathered/github_links\"\n",
    "name_owner = load_yaml(path_file)\n",
    "name_set = list(set(i.split(\"/\")[3] for i in name_owner))\n",
    "sampled_name_set = name_set[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Should I sequentially process at once and wrap it in multiprocess or apply multiprocessing first and then utilize seq afterward??\n",
    "\n",
    "\n",
    "def process_multiple(owner_multiple: list,  \n",
    "                     min_fork: int=5,\n",
    "                     min_star: int=5,\n",
    "                     updated: str=\"2020-01\",\n",
    "                     save_dir=\"all_repository\"): ## Deprecated, too many requests are needed to run, use offline processing instead\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    def single_seq(repo):\n",
    "        all_repos = get_all_repos(repo, num_load_per_page=100)\n",
    "        if all_repos is None : return \n",
    "        all_repos_json = flatten([rep.json() for rep in all_repos])\n",
    "\n",
    "        return all_repos_json\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        all_retrievals = list(executor.map(single_seq, owner_multiple))\n",
    "    \n",
    "    all_retrievals = flatten(all_retrievals)\n",
    "    all_retrievals = [repo for repo in all_retrievals if repo is not None]\n",
    "\n",
    "    print(f\"Get a total of {len(all_retrievals)} repositories\")\n",
    "\n",
    "    for rep in all_retrievals:\n",
    "\n",
    "        if not compare_dates(updated, rep[\"updated_at\"]):\n",
    "            all_retrievals.remove(rep)\n",
    "\n",
    "        elif rep[\"forks_count\"] < min_fork and rep[\"allow_forking\"]:\n",
    "            all_retrievals.remove(rep)\n",
    "        \n",
    "        elif rep[\"stargazers_count\"] < min_star:\n",
    "            all_retrievals.remove(rep)\n",
    "    \n",
    "    print(f\"Filtered out, left with {len(all_retrievals)} repositories\")\n",
    "    print(f\"Finished search repository at {time.time() - start_time}\")\n",
    "    save_json(all_retrievals, save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get a total of 35589 repositories\n",
      "Filtered out, left with 18680 repositories\n",
      "Finished search repository at 248.73885321617126\n"
     ]
    }
   ],
   "source": [
    "result001 = process_multiple(name_set[10000:15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_repository\", 'r') as f:\n",
    "    loaded_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42733"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(4798913 bytes read, 13392928 more expected)', IncompleteRead(4798913 bytes read, 13392928 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/urllib3/response.py:710\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 710\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    713\u001b[0m     \u001b[39m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[39m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/urllib3/response.py:835\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    826\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menforce_content_length\n\u001b[1;32m    827\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[39m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[1;32m    834\u001b[0m             \u001b[39m# Content-Length are caught.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m             \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_bytes_read, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength_remaining)\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m data:\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(4798913 bytes read, 13392928 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/urllib3/response.py:936\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 936\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    938\u001b[0m     \u001b[39mif\u001b[39;00m data:\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/urllib3/response.py:907\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m<\u001b[39m amt \u001b[39mand\u001b[39;00m data:\n\u001b[1;32m    904\u001b[0m     \u001b[39m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[39m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[1;32m    906\u001b[0m     \u001b[39m# it one byte at a time\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[1;32m    908\u001b[0m     decoded_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/urllib3/response.py:813\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 813\u001b[0m \u001b[39mwith\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_error_catcher():\n\u001b[1;32m    814\u001b[0m     data \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fp_closed \u001b[39melse\u001b[39;49;00m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.5/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen\u001b[39m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/urllib3/response.py:727\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39mexcept\u001b[39;00m (HTTPException, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    726\u001b[0m     \u001b[39m# This includes IncompleteRead.\u001b[39;00m\n\u001b[0;32m--> 727\u001b[0m     \u001b[39mraise\u001b[39;00m ProtocolError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConnection broken: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[39m# If no exception is thrown, we should avoid cleaning up\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \u001b[39m# unnecessarily.\u001b[39;00m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(4798913 bytes read, 13392928 more expected)', IncompleteRead(4798913 bytes read, 13392928 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/owan/Desktop/ComputeCodeX/test.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/owan/Desktop/ComputeCodeX/test.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://production-media.paperswithcode.com/about/links-between-papers-and-code.json.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    749\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/mlenv/lib/python3.11/site-packages/requests/models.py:818\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 818\u001b[0m     \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[1;32m    819\u001b[0m \u001b[39mexcept\u001b[39;00m DecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    820\u001b[0m     \u001b[39mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(4798913 bytes read, 13392928 more expected)', IncompleteRead(4798913 bytes read, 13392928 more expected))"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"https://production-media.paperswithcode.com/about/links-between-papers-and-code.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GitGatherer:\n",
    "\n",
    "    def __init__(self, log_path=\"log\", token=REQ_HEADER):\n",
    "\n",
    "        self.log_path = log_path\n",
    "        self.token_status = None \n",
    "        self.job_status : int = None \n",
    "    \n",
    "    def load_from(self, git_path):\n",
    "        self = pickle.load(git_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = GitGatherer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import data_gatherer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7036907"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_gatherer._req_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7036907"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_gatherer._req_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'gles/datasciencecoursera/contents/{+path}\",\"compare_url\":\"https://api.github.com/repos/dwiggles/datasciencecoursera/compare/{bas',\n",
       " b'ilight_decoding/notifications{?since,all,participating}\",\"labels_url\":\"https://api.github.com/repos/bergfi/milight_decoding/labe',\n",
       " b'DNN-Face-Recognition-Papers/hooks\",\"issue_events_url\":\"https://api.github.com/repos/jnulzl/DNN-Face-Recognition-Papers/issues/ev',\n",
       " b':17Z\",\"git_url\":\"git://github.com/satishjasthi/Colab-File-transfer.git\",\"ssh_url\":\"git@github.com:satishjasthi/Colab-File-transf',\n",
       " b'eveash/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/steveash/received_events\",\"type\":\"User\",\"site_admin',\n",
       " b'-Vision-in-the-Wild/GLIGEN/git/commits{/sha}\",\"comments_url\":\"https://api.github.com/repos/Computer-Vision-in-the-Wild/GLIGEN/co',\n",
       " b'\":\"https://github.com/clarinsi/meta-tagger.git\",\"svn_url\":\"https://github.com/clarinsi/meta-tagger\",\"homepage\":null,\"size\":3058,',\n",
       " b'ade_aumentada/pulls{/number}\",\"milestones_url\":\"https://api.github.com/repos/amkall/Realidade_aumentada/milestones{/number}\",\"no',\n",
       " b'_SupportingNotebooks/git/trees{/sha}\",\"statuses_url\":\"https://api.github.com/repos/JakobAsslaender/HSFP_qMT_SupportingNotebooks/',\n",
       " b'us/HexMage.NET.git\",\"clone_url\":\"https://github.com/darthdeus/HexMage.NET.git\",\"svn_url\":\"https://github.com/darthdeus/HexMage.N']"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_gatherer._req_history)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "parted = partition_list(name_set, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "    start_time = time.time()\n",
    "    queue_search = queue.Queue()\n",
    "    parted_owner = partition_list(owner_multiple, num_partition)\n",
    "    for item in parted_owner: queue_search.put(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = load_yaml(\"/Users/owan/Desktop/ComputeCodeX/data/gathered/github_links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = set(i.split(\"/\")[3] for i in rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93215"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_yaml(rep, \"/Users/owan/Desktop/ComputeCodeX/data/gathered/git_owners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
